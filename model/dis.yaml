backend: tensorflow
class_name: Model
config:
  input_layers:
  - [input_2, 0, 0]
  layers:
  - class_name: InputLayer
    config:
      batch_input_shape: !!python/tuple [1, 1, 12]
      dtype: float32
      name: input_2
      sparse: false
    inbound_nodes: []
    name: input_2
  - class_name: GRU
    config:
      activation: tanh
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      dropout: 0.0
      go_backwards: false
      implementation: 0
      kernel_constraint: null
      kernel_initializer:
        class_name: RandomNormal
        config: {mean: 0, seed: null, stddev: 0.05}
      kernel_regularizer: null
      name: gru_3
      recurrent_activation: hard_sigmoid
      recurrent_constraint: null
      recurrent_dropout: 0.0
      recurrent_initializer:
        class_name: Orthogonal
        config: {gain: 1.0, seed: null}
      recurrent_regularizer: null
      return_sequences: true
      stateful: true
      trainable: true
      units: 18
      unroll: false
      use_bias: true
    inbound_nodes:
    - - - input_2
        - 0
        - 0
        - {}
    name: gru_3
  - class_name: LeakyReLU
    config:
      alpha: !!python/object/apply:numpy.core.multiarray._reconstruct
        args:
        - &id001 !!python/name:numpy.ndarray ''
        - !!python/tuple [0]
        - !!binary |
          Yg==
        state: !!python/tuple
        - 1
        - !!python/tuple []
        - &id002 !!python/object/apply:numpy.dtype
          args: [f4, 0, 1]
          state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
        - false
        - !!binary |
          zcxMPg==
      name: leaky_re_lu_3
      trainable: true
    inbound_nodes:
    - - - gru_3
        - 0
        - 0
        - {}
    name: leaky_re_lu_3
  - class_name: Dropout
    config: {name: dropout_3, rate: 0.2, trainable: true}
    inbound_nodes:
    - - - leaky_re_lu_3
        - 0
        - 0
        - {}
    name: dropout_3
  - class_name: GRU
    config:
      activation: tanh
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      dropout: 0.0
      go_backwards: false
      implementation: 0
      kernel_constraint: null
      kernel_initializer:
        class_name: RandomNormal
        config: {mean: 0, seed: null, stddev: 0.1}
      kernel_regularizer: null
      name: gru_4
      recurrent_activation: hard_sigmoid
      recurrent_constraint: null
      recurrent_dropout: 0.0
      recurrent_initializer:
        class_name: Orthogonal
        config: {gain: 1.0, seed: null}
      recurrent_regularizer: null
      return_sequences: true
      stateful: true
      trainable: true
      units: 16
      unroll: false
      use_bias: true
    inbound_nodes:
    - - - dropout_3
        - 0
        - 0
        - {}
    name: gru_4
  - class_name: LeakyReLU
    config:
      alpha: !!python/object/apply:numpy.core.multiarray._reconstruct
        args:
        - *id001
        - !!python/tuple [0]
        - !!binary |
          Yg==
        state: !!python/tuple
        - 1
        - !!python/tuple []
        - *id002
        - false
        - !!binary |
          zcxMPg==
      name: leaky_re_lu_4
      trainable: true
    inbound_nodes:
    - - - gru_4
        - 0
        - 0
        - {}
    name: leaky_re_lu_4
  - class_name: GRU
    config:
      activation: tanh
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      dropout: 0.0
      go_backwards: false
      implementation: 0
      kernel_constraint: null
      kernel_initializer:
        class_name: RandomNormal
        config: {mean: 0, seed: null, stddev: 0.2}
      kernel_regularizer: null
      name: gru_5
      recurrent_activation: hard_sigmoid
      recurrent_constraint: null
      recurrent_dropout: 0.0
      recurrent_initializer:
        class_name: Orthogonal
        config: {gain: 1.0, seed: null}
      recurrent_regularizer: null
      return_sequences: false
      stateful: true
      trainable: true
      units: 12
      unroll: false
      use_bias: true
    inbound_nodes:
    - - - leaky_re_lu_4
        - 0
        - 0
        - {}
    name: gru_5
  - class_name: Dropout
    config: {name: dropout_4, rate: 0.2, trainable: true}
    inbound_nodes:
    - - - gru_5
        - 0
        - 0
        - {}
    name: dropout_4
  - class_name: LeakyReLU
    config:
      alpha: !!python/object/apply:numpy.core.multiarray._reconstruct
        args:
        - *id001
        - !!python/tuple [0]
        - !!binary |
          Yg==
        state: !!python/tuple
        - 1
        - !!python/tuple []
        - *id002
        - false
        - !!binary |
          zcxMPg==
      name: leaky_re_lu_5
      trainable: true
    inbound_nodes:
    - - - dropout_4
        - 0
        - 0
        - {}
    name: leaky_re_lu_5
  - class_name: Dense
    config:
      activation: linear
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      kernel_constraint: null
      kernel_initializer:
        class_name: RandomNormal
        config: {mean: 0, seed: null, stddev: 0.3}
      kernel_regularizer: null
      name: dense_2
      trainable: true
      units: 1
      use_bias: true
    inbound_nodes:
    - - - leaky_re_lu_5
        - 0
        - 0
        - {}
    name: dense_2
  - class_name: Activation
    config: {activation: tanh, name: activation_2, trainable: true}
    inbound_nodes:
    - - - dense_2
        - 0
        - 0
        - {}
    name: activation_2
  name: model_2
  output_layers:
  - [activation_2, 0, 0]
keras_version: 2.0.4
